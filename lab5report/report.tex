\documentclass[a4paper]{article}
\usepackage{latexsym}
\usepackage[a4paper]{geometry}
\usepackage{color}
\usepackage{listings}
\usepackage[pdftex]{graphicx}
\usepackage{float}

\definecolor{Blue}{rgb}{0,0,0.5}
\definecolor{Green}{rgb}{0,0.75,0.0}
\definecolor{LightGray}{rgb}{0.6,0.6,0.6}
\definecolor{DarkGray}{rgb}{0.3,0.3,0.3}
\lstset{language=Matlab,
   keywords={function,uint8,uint16,uint32,double,break,case,catch,continue,else,elseif,end,for,global,if,otherwise,persistent,return,switch,try,while},
   basicstyle=\ttfamily\small,
   breaklines=true,
   keywordstyle=\bfseries\color{Blue},
   commentstyle=\itshape\color{LightGray},
   stringstyle=\color{Green},
   numbers=left,
   numberstyle=\tiny\color{DarkGray},
   stepnumber=1,
   numbersep=10pt,
   backgroundcolor=\color{white},
   tabsize=2,
   showspaces=false,
   showstringspaces=false,
   captionpos=b}

%Boldface text for type writer font
\usepackage{bold-extra} %\DeclareFontShape{OT1}{cmtt}{bx}{n}{<5><6><7><8><9><10><10.95><12><14.4><17.28><20.74><24.88>cmttb10}{}

%Break words properly at the end of a line (which isn't sloppy...)
\sloppy

%Use command \exercise for each exercise
\newcounter{exerciseCount}
\setcounter{exerciseCount}{0}
\newcommand{\exercise}[1]{\addtocounter{exerciseCount}{1} \noindent \medskip {\large \textsf{\textbf{Exercise \arabic{exerciseCount} \--- #1}}} \par}
\renewcommand{\theenumi}{\textsf{\textbf{\alph{enumi}}}}

%Use command \code for code snippets
\newcommand{\code}[1]{\textnormal{\texttt{#1}}}

\title{\textsf{Image Processing \\ lab 5}}
\author{Klaas Kliffen \and Jan Kramer}
\date{\today}

\begin{document}
\maketitle

\exercise{Edge detection}
\begin{enumerate}
\item
    The MarrHildreth edge detection algorithm implemented here follows the steps outlined in the book.
    \begin{itemize}
        \item convolve the image with a Gaussian filter
        \item take the Laplacian of the result
        \item detect zero crossings including a threshold
    \end{itemize}
    Note that we could also have choosen to convolve the Gaussian filter with the Laplacian mask and apply that to the image with the same result.
    In addition we could have evaluated the Laplacian Gaussian function to create the filter.
    This last method has the drawback that the sum of the created filter is not neccesarily zero, which is a requirement.
    Our implemtation is as follows:
\lstinputlisting{../lab5ex1/IPMarrHildreth.m}
    Note that meshgrid is used to make the Gaussian filter.
    To get a $n\times n$ filter as in the book the arguments to meshgrid should be in the interval $[n/2, n/2]$.
    However in the case that $n$ is odd, then we get the wrong dimensions so one is substracted to correct it.
    In addition $n$ is based on the $6\sigma$ suggestion in the book.
    Next the image is padded with zeros to prevent artifacts at the edges and the filters are applied.
    The laplacian filter is the one given in to book, so there is not really something interesting there.

    After this the image is unpadded, so we can start on the zero crossing detection.
    This is done by comparing the signs of values opposite of eachother in a $3\times 3$ neighborhood.
    So there are 4 directions that have to be checked: horizontal, vertical and two diagonal directions.
    The code is based on the shifting images technique to work with these neighborhoods efficiently.
    Note that thresholding is also incorporated.
    The threshold is based on the mmaximum absolute difference in all directions.
    Alternatively we could have used the maximum absolute value, but this seemed less natural because we are comparing it with the absolute difference.
    The overal result is a binary image with twe value true on places where the edges are.
\item
    The results of applying the algorithm can be seen in Figure \ref{fig:marrhil}.
    The best result we got was the one in the upperright corner, for this one we used a $\sigma$ of $0.6\%$ of the smallest image dimension.
    While there is still some noise, most on the main edges are clearly visible.
    In the lower left corner we have a result with the same $sigma$, but without thresholding.
    The image now has way too much noise to be useful.

    The image in the lower right corner has tresholding, but only a $\sigma$ of $0.1\%$ of the smallest image dimension.
    This image shows that if the $\sigma$ is too low, some noise will show up in the results.
    Also note that there is an edge at the edge of the image.
    This is probably an implementation error, because in this case there should not be a straigth edge in the air or at the right of the house at the bricks.
    One possible reason could be that the convolution is not implemented correctly.
    Another theory is that maybe this is the result of the Gaussian filter being cut off too much.
    Or maybe the Gaussian is not calculated correctly.
    Sadly we could not confirm that any of these were the cause of the issue.
\begin{figure}[H]
\centering
\begin{tabular}{cc}
    \includegraphics[width=0.3\textwidth]{../lab5ex1/house.png} & \includegraphics[width=0.3\textwidth]{../lab5ex1/mrhouse06t15.png} \\
    The original image & $\sigma = 1.536$ and a threshold of 15\% \\
    \includegraphics[width=0.3\textwidth]{../lab5ex1/mrhouse06t0.png} & \includegraphics[width=0.3\textwidth]{../lab5ex1/mrhouse01t15.png} \\
    $\sigma = 1.536$ and a threshold of 0\% & $\sigma = 0.256$ and a threshold of 15\% \\
\end{tabular}
\caption{MarrHildreth edge detection with various parameters.}
\label{fig:marrhil}
\end{figure}
\end{enumerate}


\exercise{Region splitting and merging}
\begin{enumerate}
\item There are two main objects in the scene, the tiger and the sky. The tiger consists of a large range of grey levels and complex patterns.
The sky however is smooth and consists of a well defined range of grey levels. Therefor it less complex to define a piece of sky.
Opening Figure \ref{fig:tiger} in an image editor gave the value 107 as a lower bound for the dark regions and 168 for brighter regions.
Therefor a suitable predicate would be that all pixels in the regions are with these bounds. For the actual implementation a slightly larger bound is used,
since some areas where still a bit brighter than measured and therefor the final bounds used are $[100, 180]$.
\begin{figure}[H]
\centering
\includegraphics[width=0.4\textwidth]{../lab5ex2/tiger.png} \\
\caption{The original image with the tiger}
\label{fig:tiger}
\end{figure}

\item The predicate implementation is quite simple. It mainly consists of two large matrices used to detect values above the lower bound an below the higher bound.
The difference is taken and should sum to 0 if all values in the region are with the bounds. However, since the image is padded by the split and merge algorithm to a power of two.
It is possible that around the border of an image some values are zero in a region.
This is avoided by setting all pixels in the region with a zero grey level to 128 (a value in between the bounds).

\lstinputlisting{../lab5ex2/IPpredicate.m}



\begin{figure}[H]
\centering
\begin{tabular}{ccc}
    \includegraphics[width=0.3\textwidth]{../lab5ex2/tiger.png} & \includegraphics[width=0.3\textwidth]{../lab5ex2/block-1.png} & \includegraphics[width=0.3\textwidth]{../lab5ex2/block-2.png} \\
    Original image & Block size 1& Block size 2 \\
        \includegraphics[width=0.3\textwidth]{../lab5ex2/block-4.png} & \includegraphics[width=0.3\textwidth]{../lab5ex2/block-8.png} & \includegraphics[width=0.3\textwidth]{../lab5ex2/block-16.png} \\
    Block size 4 & Block size 8& Block size 16 \\
\end{tabular}
\caption{The partitioning scheme on the tiger image with different minimum block sizes}
\label{fig:blocks}
\end{figure}

In Figure \ref{fig:blocks} the results can be seen with various minimum block sizes. The best block size for this particular image seems to be a size of 4.
Anything smaller has too much connected blocks, where the tiger is completely invisible. 
When comparing the block size of 8 with 4, the tiger has no gaps, but the contour is less detailed. A block size of 4 still can be recognized as a tiger.
A block size of 16 is useless, since it there is no more detail to be found in the image.

\end{enumerate}

\exercise{Fourier descriptors}
\begin{enumerate}
\item
The starting point of the boundary is determined by systematically scanning each horizontal row.
It starts in the center and checks if the row has values other than the background value.
If not, two new rows are checked, each at a quarter of the image, until there are no more rows to scan and it will throw an error.
Having found the starting point, the \lstinline|bwtraceboundary|  function is called.
\lstinputlisting{../lab5ex3/IPcontour.m}
\item The starting point of the boundary using the method described above is at x: 25, y: 111.
The complete boundary can be seen in Figure \ref{fig:lincoln}
\begin{figure}[H]
\centering
\begin{tabular}{cc}
    \includegraphics[width=0.3\textwidth]{../lab5ex3/lincoln.png} & \includegraphics[width=0.3\textwidth]{../lab5ex3/contour-410.png} \\
    The original image & The contour \\
\end{tabular}
\caption{The contour of the silhouette of Lincoln}
\label{fig:lincoln}
\end{figure}

\item
The Fourier descriptors are calculated by the build in function fft.
Since the center of the array resemble the higher frequencies, the number of descriptors to be kept is at the start and the end of the array.
With a simple for loop, each of the center values can be set to 0.
The resulting approximating boundary is then retrieved by the rounding the real part of the inverse Fourier transformation.

\lstinputlisting{../lab5ex3/IPfourierdescr.m}
\item

\begin{figure}[H]
\centering
\begin{tabular}{ccc}
    \includegraphics[width=0.3\textwidth]{../lab5ex3/contour-410.png} & \includegraphics[width=0.3\textwidth]{../lab5ex3/contour-100.png} & \includegraphics[width=0.3\textwidth]{../lab5ex3/contour-75.png} \\
    Original contour (410 descriptors) & 100 descriptors & 75 descriptors \\
        \includegraphics[width=0.3\textwidth]{../lab5ex3/contour-50.png} & \includegraphics[width=0.3\textwidth]{../lab5ex3/contour-38.png} & \includegraphics[width=0.3\textwidth]{../lab5ex3/contour-25.png} \\
    50 descriptors &  38 descriptors & 25 descriptors \\
\end{tabular}
\caption{The contour of the Lincoln silhouette using different amounts of Fourier descriptors}
\label{fig:contour}
\end{figure}

As can be seen in Figure \ref{fig:contour}, the minimal number of descriptors needed for a recognizable silhouette is somewhere around 38. 
Using less descriptors will smooth the surface, where at 25 descriptors most features are smoothed and it effort to recognize the silhouette of Lincoln.

\end{enumerate}

\section*{Task distribution}

\begin{table}[H]
\centering
\begin{tabular}{ccccc}
ex1 & design & implementation & answers questions & writing report \\
\hline
Klaas & 20\% & 10\% & 20\% & 30\% \\
\hline
Jan & 80\% & 90\% & 80\% & 70\% \\
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\begin{tabular}{ccccc}
ex2 & design & implementation & answers questions & writing report \\
\hline
Klaas & 50\% & 80\% & 75\% & 75\% \\
\hline
Jan & 50\% & 20\% & 25\% & 25\% \\
\end{tabular}
\end{table}

\begin{table}[H]
\centering
\begin{tabular}{ccccc}
ex3 & design & implementation & answers questions & writing report \\
\hline
Klaas & 80\% & 75\% & 75\% & 80\% \\
\hline
Jan & 20\% & 25\% & 25\% & 20\% \\
\end{tabular}
\end{table}

\end{document}
